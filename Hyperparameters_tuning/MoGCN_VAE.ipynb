{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries reloaded!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import networks\n",
    "importlib.reload(networks)\n",
    "from networks import VAE\n",
    "\n",
    "import utils\n",
    "\n",
    "importlib.reload(utils)\n",
    "import utils.data\n",
    "importlib.reload(utils.data)\n",
    "import utils.snf\n",
    "importlib.reload(utils.snf)\n",
    "import dataset\n",
    "importlib.reload(dataset)\n",
    "\n",
    "import utils.train_val_test\n",
    "importlib.reload(utils.train_val_test)\n",
    "\n",
    "print(\"libraries reloaded!\")\n",
    "\n",
    "from utils.train_val_test import train_loop, val_loop, SEED, plot_latent_space\n",
    "from dataset import Omics_Dataset\n",
    "from utils.data import read_MoGCN_data\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim, nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.search.optuna import OptunaSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/train\"\n",
    "omics_file_names = [\"fpkm_data.csv\", \"gistic_data.csv\", \"rppa_data.csv\"]\n",
    "gt_file_name = \"sample_classes.csv\"\n",
    "\n",
    "omics_data, gt_data, samples_list, classes_list = read_MoGCN_data(\n",
    "    omics_paths=[os.path.join(data_path, file) for file in omics_file_names],\n",
    "    gt_data_path=os.path.join(data_path, gt_file_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "omics_normalised = []\n",
    "for omics in omics_data:\n",
    "    df = omics.copy()\n",
    "    values_cols = df.columns.difference([\"Sample\"])\n",
    "    df[values_cols] = (df[values_cols] - df[values_cols].min(axis=0)) / (df[values_cols].max(axis=0)-df[values_cols].min(axis=0))\n",
    "    omics_normalised.append(df)\n",
    "    print(len(omics_normalised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "omics_file_names = [\"fpkm_data\", \"gistic_data\", \"rppa_data\"]\n",
    "\n",
    "for i in range(len(omics_normalised)):\n",
    "    omics_normalised[i] = omics_normalised[i].dropna(axis=1)\n",
    "    omics_normalised[i] = omics_normalised[i].rename(columns={\"Sample\": \"Sample_ID\"})\n",
    "    omics_normalised[i].to_csv(data_path+\"/\"+ omics_file_names[i]+\"_norm.csv\",  index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/train\"\n",
    "omics_file_names = [\"fpkm_data_norm.csv\", \"gistic_data_norm.csv\", \"rppa_data_norm.csv\"]\n",
    "gt_file_name = \"sample_classes.csv\"\n",
    "\n",
    "omics_data, gt_data, samples_list, classes_list = read_MoGCN_data(\n",
    "    omics_paths=[os.path.join(data_path, file) for file in omics_file_names],\n",
    "    gt_data_path=os.path.join(data_path, gt_file_name),\n",
    ")\n",
    "\n",
    "x_train , x_val, y_train, y_val = train_test_split(omics_data[1], gt_data, test_size=0.2, stratify=classes_list)\n",
    "\n",
    "MoGCN_train = Omics_Dataset(x_train, y_train)\n",
    "MoGCN_val = Omics_Dataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    config,\n",
    "    hyper_loop,\n",
    "    num_samples,\n",
    "    search_dir=None,\n",
    "    search_alg=None,\n",
    "    local_dir=\"/home/davide/Desktop/Projects/Multi-omics-data-integration-with-DL-approaches/Hyperparameters_tuning/results\",\n",
    "):  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=100,\n",
    "        grace_period=10,\n",
    "        reduction_factor=3,\n",
    "        brackets=1,\n",
    "    )\n",
    "\n",
    "    if not search_alg:\n",
    "        search_alg = OptunaSearch(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "        )\n",
    "\n",
    "    result = tune.run(\n",
    "        hyper_loop,\n",
    "        config=config,\n",
    "        resources_per_trial={\"cpu\": 6, \"gpu\": 1},\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search_alg,\n",
    "        num_samples=num_samples,\n",
    "        local_dir=(local_dir),\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "    \n",
    "    if search_dir:\n",
    "        search_alg.save(search_dir)\n",
    "\n",
    "    return best_trial\n",
    "\n",
    "\n",
    "def hyper_loop(config):\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        MoGCN_train, batch_size=int(config[\"batch_size\"]), shuffle=True\n",
    "    )\n",
    "\n",
    "    valloader = DataLoader(\n",
    "        MoGCN_val, batch_size=int(config[\"batch_size\"]), shuffle=True\n",
    "    )\n",
    "    net = VAE(\n",
    "        MoGCN_train.input_dims,\n",
    "        config[\"model_name\"],\n",
    "        activation_fn=config[\"activation_fn\"],\n",
    "        dropout_p=config[\"dropout_p\"],\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        latent_dim=config[\"latent_dim\"],\n",
    "        loss_fn=config[\"loss_fn\"],\n",
    "        beta=config[\"beta\"],\n",
    "    )\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    for epoch in range(30):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, (inputs, _) in enumerate(trainloader):\n",
    "            # forward + backward + optimize\n",
    "            outputs, loss = net.forward_pass(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        for i, (inputs, _) in enumerate(valloader):\n",
    "            with torch.no_grad():\n",
    "                outputs, loss = net.forward_pass(inputs)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "\n",
    "        train.report({\"loss\": (val_loss / len(valloader))})\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5e-6, 0.01005, 5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.arange(5e-6, 0.01005, 5e-6))\n",
    "# np.linspace(start = 0.0, stop = 0.8, num= 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 15:09:36,407\tINFO tune.py:645 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2023-11-03 15:09:36,548] A new study created in memory with name: optuna\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-03 15:12:00</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:23.51        </td></tr>\n",
       "<tr><td>Memory:      </td><td>14.3/15.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=11<br>Bracket: Iter 90.000: None | Iter 30.000: -0.03325371278656854 | Iter 10.000: -0.03206555338369475<br>Logical resource usage: 6.0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>hyper_loop_6ec5861a</td><td>RUNNING   </td><td>192.168.0.14:46853</td><td style=\"text-align: right;\">0.05 </td><td style=\"text-align: right;\">         0.095</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         5.43717</td><td style=\"text-align: right;\">0.0320486</td></tr>\n",
       "<tr><td>hyper_loop_ed3a57ae</td><td>PENDING   </td><td>                  </td><td style=\"text-align: right;\">0.175</td><td style=\"text-align: right;\">         0.195</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>hyper_loop_bfb0841e</td><td>TERMINATED</td><td>192.168.0.14:45902</td><td style=\"text-align: right;\">0.08 </td><td style=\"text-align: right;\">         0.16 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.91647</td><td style=\"text-align: right;\">0.0404707</td></tr>\n",
       "<tr><td>hyper_loop_7d133486</td><td>TERMINATED</td><td>192.168.0.14:45951</td><td style=\"text-align: right;\">0.07 </td><td style=\"text-align: right;\">         0.03 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         6.10721</td><td style=\"text-align: right;\">0.032625 </td></tr>\n",
       "<tr><td>hyper_loop_c70fbe8e</td><td>TERMINATED</td><td>192.168.0.14:46001</td><td style=\"text-align: right;\">0.155</td><td style=\"text-align: right;\">         0.075</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.75002</td><td style=\"text-align: right;\">1.96057  </td></tr>\n",
       "<tr><td>hyper_loop_67cf12ff</td><td>TERMINATED</td><td>192.168.0.14:46050</td><td style=\"text-align: right;\">0.13 </td><td style=\"text-align: right;\">         0.055</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.20415</td><td style=\"text-align: right;\">0.0329652</td></tr>\n",
       "<tr><td>hyper_loop_827a36d0</td><td>TERMINATED</td><td>192.168.0.14:46121</td><td style=\"text-align: right;\">0.125</td><td style=\"text-align: right;\">         0.11 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.73806</td><td style=\"text-align: right;\">0.485066 </td></tr>\n",
       "<tr><td>hyper_loop_317bbd62</td><td>TERMINATED</td><td>192.168.0.14:46172</td><td style=\"text-align: right;\">0.19 </td><td style=\"text-align: right;\">         0.19 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.21297</td><td style=\"text-align: right;\">0.0450201</td></tr>\n",
       "<tr><td>hyper_loop_1e616913</td><td>TERMINATED</td><td>192.168.0.14:46215</td><td style=\"text-align: right;\">0.115</td><td style=\"text-align: right;\">         0.14 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.9596 </td><td style=\"text-align: right;\">0.232066 </td></tr>\n",
       "<tr><td>hyper_loop_5a68116e</td><td>TERMINATED</td><td>192.168.0.14:46372</td><td style=\"text-align: right;\">0.195</td><td style=\"text-align: right;\">         0.06 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.40991</td><td style=\"text-align: right;\">1.58724  </td></tr>\n",
       "<tr><td>hyper_loop_6c476378</td><td>TERMINATED</td><td>192.168.0.14:46434</td><td style=\"text-align: right;\">0.165</td><td style=\"text-align: right;\">         0.025</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.99456</td><td style=\"text-align: right;\">2.41825  </td></tr>\n",
       "<tr><td>hyper_loop_3421395d</td><td>TERMINATED</td><td>192.168.0.14:46477</td><td style=\"text-align: right;\">0.04 </td><td style=\"text-align: right;\">         0.155</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.76438</td><td style=\"text-align: right;\">0.0358157</td></tr>\n",
       "<tr><td>hyper_loop_06f844f5</td><td>TERMINATED</td><td>192.168.0.14:46520</td><td style=\"text-align: right;\">0.115</td><td style=\"text-align: right;\">         0.055</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.63001</td><td style=\"text-align: right;\">0.0335681</td></tr>\n",
       "<tr><td>hyper_loop_c316e831</td><td>TERMINATED</td><td>192.168.0.14:46563</td><td style=\"text-align: right;\">0.07 </td><td style=\"text-align: right;\">         0.03 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.60585</td><td style=\"text-align: right;\">0.0324542</td></tr>\n",
       "<tr><td>hyper_loop_c86893ac</td><td>TERMINATED</td><td>192.168.0.14:46615</td><td style=\"text-align: right;\">0.13 </td><td style=\"text-align: right;\">         0.125</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.94235</td><td style=\"text-align: right;\">0.033227 </td></tr>\n",
       "<tr><td>hyper_loop_b07a4718</td><td>TERMINATED</td><td>192.168.0.14:46661</td><td style=\"text-align: right;\">0.07 </td><td style=\"text-align: right;\">         0.03 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.83813</td><td style=\"text-align: right;\">0.0321259</td></tr>\n",
       "<tr><td>hyper_loop_669da411</td><td>TERMINATED</td><td>192.168.0.14:46707</td><td style=\"text-align: right;\">0.07 </td><td style=\"text-align: right;\">         0.03 </td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.90078</td><td style=\"text-align: right;\">0.0318113</td></tr>\n",
       "<tr><td>hyper_loop_33ad3161</td><td>TERMINATED</td><td>192.168.0.14:46759</td><td style=\"text-align: right;\">0.07 </td><td style=\"text-align: right;\">         0.03 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.92678</td><td style=\"text-align: right;\">0.0324512</td></tr>\n",
       "<tr><td>hyper_loop_7e2bd8a3</td><td>TERMINATED</td><td>192.168.0.14:46806</td><td style=\"text-align: right;\">0.2  </td><td style=\"text-align: right;\">         0.18 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.88954</td><td style=\"text-align: right;\">0.0353855</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 15:09:37,013\tWARNING worker.py:2058 -- Warning: The actor ImplicitFunc is very large (31 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th style=\"text-align: right;\">     loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>hyper_loop_06f844f5</td><td style=\"text-align: right;\">0.0335681</td></tr>\n",
       "<tr><td>hyper_loop_1e616913</td><td style=\"text-align: right;\">0.232066 </td></tr>\n",
       "<tr><td>hyper_loop_317bbd62</td><td style=\"text-align: right;\">0.0450201</td></tr>\n",
       "<tr><td>hyper_loop_33ad3161</td><td style=\"text-align: right;\">0.0324512</td></tr>\n",
       "<tr><td>hyper_loop_3421395d</td><td style=\"text-align: right;\">0.0358157</td></tr>\n",
       "<tr><td>hyper_loop_5a68116e</td><td style=\"text-align: right;\">1.58724  </td></tr>\n",
       "<tr><td>hyper_loop_669da411</td><td style=\"text-align: right;\">0.0318113</td></tr>\n",
       "<tr><td>hyper_loop_67cf12ff</td><td style=\"text-align: right;\">0.0329652</td></tr>\n",
       "<tr><td>hyper_loop_6c476378</td><td style=\"text-align: right;\">2.41825  </td></tr>\n",
       "<tr><td>hyper_loop_6ec5861a</td><td style=\"text-align: right;\">0.14695  </td></tr>\n",
       "<tr><td>hyper_loop_7d133486</td><td style=\"text-align: right;\">0.032625 </td></tr>\n",
       "<tr><td>hyper_loop_7e2bd8a3</td><td style=\"text-align: right;\">0.0353855</td></tr>\n",
       "<tr><td>hyper_loop_827a36d0</td><td style=\"text-align: right;\">0.485066 </td></tr>\n",
       "<tr><td>hyper_loop_b07a4718</td><td style=\"text-align: right;\">0.0321259</td></tr>\n",
       "<tr><td>hyper_loop_bfb0841e</td><td style=\"text-align: right;\">0.0404707</td></tr>\n",
       "<tr><td>hyper_loop_c316e831</td><td style=\"text-align: right;\">0.0324542</td></tr>\n",
       "<tr><td>hyper_loop_c70fbe8e</td><td style=\"text-align: right;\">1.96057  </td></tr>\n",
       "<tr><td>hyper_loop_c86893ac</td><td style=\"text-align: right;\">0.033227 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(hyper_loop pid=45902)\u001b[0m Finished Training\n",
      "\u001b[2m\u001b[36m(hyper_loop pid=45951)\u001b[0m Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-03 15:10:36,340 E 35172 35172] (raylet) node_manager.cc:3007: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7100ecaa6ba4f9bbe1dfcd91819869b7c4fdd036e29d983f9c9898cb, IP: 192.168.0.14) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 192.168.0.14`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(hyper_loop pid=46477)\u001b[0m Finished Training\n",
      "\u001b[2m\u001b[36m(hyper_loop pid=46520)\u001b[0m Finished Training\n",
      "\u001b[2m\u001b[36m(hyper_loop pid=46563)\u001b[0m Finished Training\n",
      "\u001b[2m\u001b[36m(hyper_loop pid=46707)\u001b[0m Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 15:12:00,053\tWARNING tune.py:194 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-11-03 15:12:00,097\tINFO tune.py:1143 -- Total run time: 143.69 seconds (143.50 seconds for the tuning loop).\n",
      "2023-11-03 15:12:00,098\tWARNING tune.py:1158 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2023-11-03 15:12:00,129\tWARNING experiment_analysis.py:205 -- Failed to fetch metrics for 1 trial(s):\n",
      "- hyper_loop_ed3a57ae: FileNotFoundError('Could not fetch metrics for hyper_loop_ed3a57ae: both result.json and progress.csv were not found at /home/davide/Desktop/Projects/Multi-omics-data-integration-with-DL-approaches/Hyperparameters_tuning/results/hyper_loop_2023-11-03_15-09-36/hyper_loop_ed3a57ae_19_activation_fn=ref_ph_ab5d744a,batch_size=32,beta=1,dropout_p=0.0000,hidden_dim=128,latent_dim=32,loss_fn=re_2023-11-03_15-11-54')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'model_name': 'VAE_omics_1', 'activation_fn': Sigmoid(), 'dropout_p': 0.0, 'hidden_dim': 128, 'latent_dim': 32, 'loss_fn': MSELoss(), 'beta': 1, 'lr': 0.07, 'weight_decay': 0.030000000000000002, 'batch_size': 32}\n",
      "Best trial final validation loss: 0.03181132425864538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hyper_loop_669da411"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-11-03 15:15:36,345 E 35172 35172] (raylet) node_manager.cc:3007: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7100ecaa6ba4f9bbe1dfcd91819869b7c4fdd036e29d983f9c9898cb, IP: 192.168.0.14) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 192.168.0.14`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"model_name\": \"VAE_omics_1\",\n",
    "    # \"activation_fn\": tune.choice([nn.Sigmoid(), nn.ELU(), nn.LeakyReLU()]),\n",
    "    \"activation_fn\": nn.Sigmoid(),\n",
    "    # \"dropout_p\": tune.quniform(0.0, 0.8, 0.1),\n",
    "    # \"dropout_p\": tune.choice(np.arange(start = 0.0, stop = 0.9, step= 0.1)),\n",
    "    \"dropout_p\": 0.0,\n",
    "    # \"hidden_dim\": tune.choice([2**i for i in range(1, 8)]),\n",
    "    \"hidden_dim\": 128,\n",
    "    # \"latent_dim\": tune.choice([2**i for i in range(1, 8)]),\n",
    "    \"latent_dim\": 32,\n",
    "    \"loss_fn\": nn.MSELoss(reduction=\"mean\"),\n",
    "    # \"beta\": tune.loguniform(1e-6, 0.1),\n",
    "    \"beta\": 1,\n",
    "    # \"lr\": tune.loguniform(1e-3, 1e-1),\n",
    "    \"lr\": tune.choice(np.arange(0.005, 0.205, 0.005)),\n",
    "    # \"weight_decay\": tune.loguniform(1e-3, 1e-1),\n",
    "    \"weight_decay\": tune.choice(np.arange(0.005, 0.205, 0.005)),\n",
    "    # \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "search_alg = OptunaSearch(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "main(config, hyper_loop, 50, \"./checkpoints/omics_1/tune_search.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
