{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original vs Stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import read_MoGCN_data\n",
    "import os\n",
    "\n",
    "data_path = \"./data/MoGCN/\"\n",
    "omics_file_names = [\"fpkm_data.csv\", \"gistic_data.csv\", \"rppa_data.csv\"]\n",
    "gt_file_name = \"sample_classes.csv\"\n",
    "\n",
    "omics_data, gt_data, samples_list, classes_list = read_MoGCN_data(\n",
    "    omics_paths=[os.path.join(data_path, file) for file in omics_file_names],\n",
    "    gt_data_path=os.path.join(data_path, gt_file_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions of MoGCN train-test splits for each class\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.data import read_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "test_sample = read_data(os.path.join(data_path, \"test_sample.csv\"))\n",
    "train_sample = read_data(os.path.join(data_path, \"train_sample.csv\"))\n",
    "\n",
    "test_data = gt_data.loc[gt_data[\"Sample\"].isin(test_sample[\"Sample\"])].copy()\n",
    "test_data[\"type\"]=\"test\"\n",
    "train_data = gt_data.loc[gt_data[\"Sample\"].isin(train_sample[\"Sample\"])].copy()\n",
    "train_data[\"type\"]=\"train\"\n",
    "\n",
    "sampled_data = pd.concat([test_data, train_data], ignore_index=True)\n",
    "\n",
    "sns.histplot(x=sampled_data[\"PAM50Call_RNAseq\"], hue=sampled_data[\"type\"], multiple = \"fill\")\n",
    "print(\"Proportions of MoGCN train-test splits for each class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions of Stratified train-test splits for each class\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(omics_data[0],gt_data,test_size=0.15, stratify=gt_data[\"class\"]) \n",
    "\n",
    "y[\"type\"] = \"train\"\n",
    "y_test[\"type\"] = \"test\"\n",
    "\n",
    "strat_data = pd.concat([y_test, y], ignore_index=True)\n",
    "\n",
    "sns.histplot(x=strat_data[\"PAM50Call_RNAseq\"], hue=strat_data[\"type\"], multiple = \"fill\")\n",
    "print(\"Proportions of Stratified train-test splits for each class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-organise data folder structure and save stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import make_path, read_MoGCN_data, read_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "def data_to_csv(omics_data, gt_data, samples, output_path):\n",
    "    make_path(output_path)\n",
    "\n",
    "    omics_file_names = [\"fpkm_data.csv\", \"gistic_data.csv\", \"rppa_data.csv\"]\n",
    "\n",
    "    for i in range(len(omics_file_names)):\n",
    "        save_path = os.path.join(output_path, omics_file_names[i])\n",
    "        data = omics_data[i].copy()\n",
    "        filtered = data.loc[data[\"Sample\"].isin(samples)].reset_index(drop=True).copy()\n",
    "        filtered.to_csv(save_path, index=False)\n",
    "\n",
    "    gt_file_name = \"sample_classes.csv\"\n",
    "    save_path = os.path.join(output_path, gt_file_name)\n",
    "\n",
    "    filtered = (\n",
    "        gt_data.loc[gt_data[\"Sample\"].isin(samples)].reset_index(drop=True).copy()\n",
    "    )\n",
    "    filtered.to_csv(save_path, index=False)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "data_path = \"./data/MoGCN/\"\n",
    "omics_file_names = [\"fpkm_data.csv\", \"gistic_data.csv\", \"rppa_data.csv\"]\n",
    "gt_file_name = \"sample_classes.csv\"\n",
    "\n",
    "# Load all MoGCN data\n",
    "omics_data, gt_data, samples_list, classes_list = read_MoGCN_data(\n",
    "    omics_paths=[os.path.join(data_path, file) for file in omics_file_names],\n",
    "    gt_data_path=os.path.join(data_path, gt_file_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and save original splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original splits\n",
    "train_samples = read_data(\"./data/MoGCN/train_sample.csv\")[\"Sample\"]\n",
    "test_samples = read_data(\"./data/MoGCN/test_sample.csv\")[\"Sample\"]\n",
    "\n",
    "# Save splits to csv\n",
    "data_to_csv(omics_data, gt_data, train_samples, \"./data/original_split/train\")\n",
    "data_to_csv(omics_data, gt_data, test_samples, \"./data/original_split/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and save stratified splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.15\n",
    "\n",
    "# Split into train-test\n",
    "x, x_test, y, y_test = train_test_split(\n",
    "    omics_data[0], gt_data, test_size=test_size, stratify=gt_data[\"class\"]\n",
    ")\n",
    "\n",
    "# Save splits to csv\n",
    "test_samples = y_test[\"Sample\"]\n",
    "train_samples = y[\"Sample\"]\n",
    "\n",
    "\n",
    "# data_to_csv(omics_data, gt_data, train_samples, \"./data/stratified_split/train\")\n",
    "# data_to_csv(omics_data, gt_data, test_samples, \"./data/stratified_split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "434\n",
      "434\n",
      "434\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/stratified_split/train/\"\n",
    "omics_file_names = [\"fpkm_data.csv\", \"gistic_data.csv\", \"rppa_data.csv\"]\n",
    "gt_file_name = \"sample_classes.csv\"\n",
    "\n",
    "omics_data, gt_data, samples_list, classes_list = read_MoGCN_data(\n",
    "    omics_paths=[os.path.join(data_path, file) for file in omics_file_names],\n",
    "    gt_data_path=os.path.join(data_path, gt_file_name),\n",
    ")\n",
    "\n",
    "for omics in omics_data:\n",
    "    print(len(omics))\n",
    "\n",
    "print(len(gt_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "77\n",
      "77\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/stratified_split/test/\"\n",
    "omics_file_names = [\"fpkm_data.csv\", \"gistic_data.csv\", \"rppa_data.csv\"]\n",
    "gt_file_name = \"sample_classes.csv\"\n",
    "\n",
    "omics_data, gt_data, samples_list, classes_list = read_MoGCN_data(\n",
    "    omics_paths=[os.path.join(data_path, file) for file in omics_file_names],\n",
    "    gt_data_path=os.path.join(data_path, gt_file_name),\n",
    ")\n",
    "\n",
    "for omics in omics_data:\n",
    "    print(len(omics))\n",
    "\n",
    "print(len(gt_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from running their GitHub repo (original split)\n",
    "#### **Note: code shares training data (AE latent space, SNF fused network) when testing GCN**\n",
    "\n",
    "\n",
    "- predict label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 0 0 0 0 0 0 2 0 0\n",
    " 2 0 2 1 0 1 0 0 0 2 0 0 1 1 1 0 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
    "- original label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 1 0 0 0 0 0 2 0 0\n",
    " 2 0 2 1 0 1 1 0 0 2 1 0 1 1 0 1 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
    " \n",
    "- Test set results: loss= 0.1365 accuracy= 0.9265\n",
    "- Acc(0.9265, 0.0000)  F1(0.9334, 0.0000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "epoch: 1 | loss: 63.7949\n",
      "epoch: 2 | loss: 40.6257\n",
      "epoch: 3 | loss: 26.1860\n",
      "epoch: 4 | loss: 17.4162\n",
      "epoch: 5 | loss: 12.2317\n",
      "epoch: 6 | loss: 9.2268\n",
      "epoch: 7 | loss: 7.4781\n",
      "epoch: 8 | loss: 6.4419\n",
      "epoch: 9 | loss: 5.8268\n",
      "epoch: 10 | loss: 5.4522\n",
      "epoch: 11 | loss: 5.2107\n",
      "epoch: 12 | loss: 5.0522\n",
      "epoch: 13 | loss: 4.9372\n",
      "epoch: 14 | loss: 4.8558\n",
      "epoch: 15 | loss: 4.7836\n",
      "epoch: 16 | loss: 4.7273\n",
      "epoch: 17 | loss: 4.6703\n",
      "epoch: 18 | loss: 4.6185\n",
      "epoch: 19 | loss: 4.5668\n",
      "epoch: 20 | loss: 4.5157\n",
      "epoch: 21 | loss: 4.4672\n",
      "epoch: 22 | loss: 4.4239\n",
      "epoch: 23 | loss: 4.3898\n",
      "epoch: 24 | loss: 4.3430\n",
      "epoch: 25 | loss: 4.3076\n",
      "epoch: 26 | loss: 4.2593\n",
      "epoch: 27 | loss: 4.2175\n",
      "epoch: 28 | loss: 4.1830\n",
      "epoch: 29 | loss: 4.1420\n",
      "epoch: 30 | loss: 4.1097\n",
      "epoch: 31 | loss: 4.0718\n",
      "epoch: 32 | loss: 4.0398\n",
      "epoch: 33 | loss: 4.0098\n",
      "epoch: 34 | loss: 3.9853\n",
      "epoch: 35 | loss: 3.9578\n",
      "epoch: 36 | loss: 3.9121\n",
      "epoch: 37 | loss: 3.8838\n",
      "epoch: 38 | loss: 3.8691\n",
      "epoch: 39 | loss: 3.8361\n",
      "epoch: 40 | loss: 3.8142\n",
      "epoch: 41 | loss: 3.7799\n",
      "epoch: 42 | loss: 3.7522\n",
      "epoch: 43 | loss: 3.7226\n",
      "epoch: 44 | loss: 3.7017\n",
      "epoch: 45 | loss: 3.6699\n",
      "epoch: 46 | loss: 3.6629\n",
      "epoch: 47 | loss: 3.6254\n",
      "epoch: 48 | loss: 3.5978\n",
      "epoch: 49 | loss: 3.5620\n",
      "epoch: 50 | loss: 3.5450\n",
      "epoch: 51 | loss: 3.5307\n",
      "epoch: 52 | loss: 3.5180\n",
      "epoch: 53 | loss: 3.4817\n",
      "epoch: 54 | loss: 3.4617\n",
      "epoch: 55 | loss: 3.4347\n",
      "epoch: 56 | loss: 3.3963\n",
      "epoch: 57 | loss: 3.4046\n",
      "epoch: 58 | loss: 3.3691\n",
      "epoch: 59 | loss: 3.3525\n",
      "epoch: 60 | loss: 3.3389\n",
      "epoch: 61 | loss: 3.3071\n",
      "epoch: 62 | loss: 3.2749\n",
      "epoch: 63 | loss: 3.2626\n",
      "epoch: 64 | loss: 3.2431\n",
      "epoch: 65 | loss: 3.2506\n",
      "epoch: 66 | loss: 3.2216\n",
      "epoch: 67 | loss: 3.1927\n",
      "epoch: 68 | loss: 3.1768\n",
      "epoch: 69 | loss: 3.1374\n",
      "epoch: 70 | loss: 3.1433\n",
      "epoch: 71 | loss: 3.1151\n",
      "epoch: 72 | loss: 3.0971\n",
      "epoch: 73 | loss: 3.0735\n",
      "epoch: 74 | loss: 3.0519\n",
      "epoch: 75 | loss: 3.0504\n",
      "epoch: 76 | loss: 3.0196\n",
      "epoch: 77 | loss: 3.0045\n",
      "epoch: 78 | loss: 2.9977\n",
      "epoch: 79 | loss: 2.9926\n",
      "epoch: 80 | loss: 2.9721\n",
      "epoch: 81 | loss: 2.9402\n",
      "epoch: 82 | loss: 2.9352\n",
      "epoch: 83 | loss: 2.9356\n",
      "epoch: 84 | loss: 2.9066\n",
      "epoch: 85 | loss: 2.9088\n",
      "epoch: 86 | loss: 2.8749\n",
      "epoch: 87 | loss: 2.8613\n",
      "epoch: 88 | loss: 2.8499\n",
      "epoch: 89 | loss: 2.8418\n",
      "epoch: 90 | loss: 2.8385\n",
      "epoch: 91 | loss: 2.8308\n",
      "epoch: 92 | loss: 2.8151\n",
      "epoch: 93 | loss: 2.8211\n",
      "epoch: 94 | loss: 2.7804\n",
      "epoch: 95 | loss: 2.7750\n",
      "epoch: 96 | loss: 2.7423\n",
      "epoch: 97 | loss: 2.7555\n",
      "epoch: 98 | loss: 2.7445\n",
      "epoch: 99 | loss: 2.7239\n",
      "epoch: 100 | loss: 2.7055\n",
      "Get the latent layer output...\n",
      "Success! Results can be seen in result file\n"
     ]
    }
   ],
   "source": [
    "!python ../Models/MoGCN/AE_run.py -p1 ./data/fpkm_data.csv -p2 ./data/gistic_data.csv -p3 ./data/rppa_data.csv -m 0 -s 0 -d cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data files...\n",
      "(511, 19581) (511, 19274) (511, 224)\n",
      "Start similarity network fusion...\n",
      "Save fused adjacency matrix...\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:530: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage = hierarchy.linkage(self.array, method=self.method,\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:530: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage = hierarchy.linkage(self.array, method=self.method,\n",
      "Success! Results can be seen in result file\n"
     ]
    }
   ],
   "source": [
    "!python ../Models/MoGCN/SNF.py -p ./data/fpkm_data.csv ./data/gistic_data.csv ./data/rppa_data.csv -m sqeuclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Calculating the laplace adjacency matrix...\n",
      "Begin training model...\n",
      "Epoch: 10.00 | loss train: 1.2102 | acc train: 0.4808\n",
      "Epoch: 20.00 | loss train: 1.0925 | acc train: 0.5305\n",
      "Epoch: 30.00 | loss train: 0.9462 | acc train: 0.6614\n",
      "Epoch: 40.00 | loss train: 0.7426 | acc train: 0.7223\n",
      "Epoch: 50.00 | loss train: 0.5765 | acc train: 0.7788\n",
      "Epoch: 60.00 | loss train: 0.4773 | acc train: 0.8375\n",
      "Epoch: 70.00 | loss train: 0.4303 | acc train: 0.8510\n",
      "Epoch: 80.00 | loss train: 0.3768 | acc train: 0.8736\n",
      "Epoch: 90.00 | loss train: 0.3586 | acc train: 0.8781\n",
      "Epoch: 100.00 | loss train: 0.3171 | acc train: 0.9007\n",
      "Epoch: 110.00 | loss train: 0.3018 | acc train: 0.8984\n",
      "Epoch: 120.00 | loss train: 0.2886 | acc train: 0.9142\n",
      "Epoch: 130.00 | loss train: 0.2900 | acc train: 0.9097\n",
      "Epoch: 140.00 | loss train: 0.2697 | acc train: 0.9097\n",
      "Epoch: 150.00 | loss train: 0.2858 | acc train: 0.9074\n",
      "Training finished.\n",
      "The best epoch model is  145\n",
      "predict label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 0 0 0 0 0 0 2 0 0\n",
      " 2 0 2 1 0 1 0 0 0 2 0 0 1 1 1 0 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
      "original label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 1 0 0 0 0 0 2 0 0\n",
      " 2 0 2 1 0 1 1 0 0 2 1 0 1 1 0 1 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
      "Test set results: loss= 0.1365 accuracy= 0.9265\n",
      "Acc(0.9265, 0.0000)  F1(0.9334, 0.0000)\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "!python ../Models/MoGCN/GCN_run.py -fd result/latent_data.csv -ad result/SNF_fused_matrix.csv -ld ./data/sample_classes.csv -ts ./data/test_sample.csv -m 1 -d gpu -p 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Calculating the laplace adjacency matrix...\n",
      "Begin training model...\n",
      "Epoch: 10.00 | loss train: 1.1975 | acc train: 0.4858\n",
      "Epoch: 20.00 | loss train: 1.0805 | acc train: 0.5839\n",
      "Epoch: 30.00 | loss train: 0.9282 | acc train: 0.6819\n",
      "Epoch: 40.00 | loss train: 0.7247 | acc train: 0.7190\n",
      "Epoch: 50.00 | loss train: 0.5636 | acc train: 0.7800\n",
      "Epoch: 60.00 | loss train: 0.4659 | acc train: 0.8366\n",
      "Epoch: 70.00 | loss train: 0.4181 | acc train: 0.8584\n",
      "Epoch: 80.00 | loss train: 0.3604 | acc train: 0.8780\n",
      "Epoch: 90.00 | loss train: 0.3412 | acc train: 0.8824\n",
      "Epoch: 100.00 | loss train: 0.3051 | acc train: 0.9085\n",
      "Epoch: 110.00 | loss train: 0.2874 | acc train: 0.9020\n",
      "Epoch: 120.00 | loss train: 0.2710 | acc train: 0.9085\n",
      "Epoch: 130.00 | loss train: 0.2753 | acc train: 0.9085\n",
      "Epoch: 140.00 | loss train: 0.2506 | acc train: 0.9063\n",
      "Epoch: 150.00 | loss train: 0.2563 | acc train: 0.9172\n",
      "predict label:  [2 3 0 0 0 0 0 3 0 0 2 2 1 2 2 1 0 0 0 3 0 0 0 0 2 0 0 3 0 3 0 0 2 3 0 0 1\n",
      " 0 1 0 0 2 2 3 2 0 2 3 0 1 0 0]\n",
      "original label:  [2 3 0 0 0 0 0 3 0 0 2 2 1 2 2 0 0 0 0 3 0 0 0 0 2 0 0 3 0 3 1 0 2 1 1 0 1\n",
      " 0 1 0 0 2 2 3 2 1 2 1 0 1 0 1]\n",
      "Test set results: loss= 0.2880 accuracy= 0.8654\n",
      "Epoch: 10.00 | loss train: 1.1965 | acc train: 0.4891\n",
      "Epoch: 20.00 | loss train: 1.0333 | acc train: 0.6587\n",
      "Epoch: 30.00 | loss train: 0.8378 | acc train: 0.7022\n",
      "Epoch: 40.00 | loss train: 0.6480 | acc train: 0.7370\n",
      "Epoch: 50.00 | loss train: 0.5252 | acc train: 0.8087\n",
      "Epoch: 60.00 | loss train: 0.4436 | acc train: 0.8457\n",
      "Epoch: 70.00 | loss train: 0.3954 | acc train: 0.8696\n",
      "Epoch: 80.00 | loss train: 0.3595 | acc train: 0.8739\n",
      "Epoch: 90.00 | loss train: 0.3177 | acc train: 0.8935\n",
      "Epoch: 100.00 | loss train: 0.2969 | acc train: 0.9022\n",
      "Epoch: 110.00 | loss train: 0.2955 | acc train: 0.9022\n",
      "Epoch: 120.00 | loss train: 0.2844 | acc train: 0.9043\n",
      "Epoch: 130.00 | loss train: 0.3001 | acc train: 0.8978\n",
      "Epoch: 140.00 | loss train: 0.2776 | acc train: 0.9022\n",
      "Epoch: 150.00 | loss train: 0.2538 | acc train: 0.9087\n",
      "predict label:  [2 3 0 1 0 0 0 1 3 1 2 2 0 2 2 2 1 0 2 0 0 1 0 0 2 0 0 0 0 3 3 2 2 3 3 1 0\n",
      " 0 1 0 0 0 3 0 0 0 1 0 1 0 0]\n",
      "original label:  [2 3 0 1 1 0 0 1 3 1 2 2 0 2 2 2 1 0 2 0 0 1 0 0 2 0 0 0 0 3 3 2 2 3 2 1 0\n",
      " 0 1 0 0 0 3 0 0 0 1 0 0 0 0]\n",
      "Test set results: loss= 0.2148 accuracy= 0.9412\n",
      "Epoch: 10.00 | loss train: 1.1614 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0338 | acc train: 0.5761\n",
      "Epoch: 30.00 | loss train: 0.8647 | acc train: 0.7109\n",
      "Epoch: 40.00 | loss train: 0.6839 | acc train: 0.7543\n",
      "Epoch: 50.00 | loss train: 0.5413 | acc train: 0.7891\n",
      "Epoch: 60.00 | loss train: 0.4301 | acc train: 0.8522\n",
      "Epoch: 70.00 | loss train: 0.3677 | acc train: 0.8783\n",
      "Epoch: 80.00 | loss train: 0.3271 | acc train: 0.8783\n",
      "Epoch: 90.00 | loss train: 0.3067 | acc train: 0.9043\n",
      "Epoch: 100.00 | loss train: 0.2783 | acc train: 0.9000\n",
      "Epoch: 110.00 | loss train: 0.2910 | acc train: 0.9000\n",
      "Epoch: 120.00 | loss train: 0.2613 | acc train: 0.9196\n",
      "Epoch: 130.00 | loss train: 0.2753 | acc train: 0.9217\n",
      "Epoch: 140.00 | loss train: 0.2477 | acc train: 0.9174\n",
      "Epoch: 150.00 | loss train: 0.2395 | acc train: 0.9174\n",
      "predict label:  [0 0 1 0 0 0 2 2 0 3 0 0 0 2 2 0 0 0 3 0 2 0 2 2 0 0 0 0 1 1 1 2 3 0 3 1 3\n",
      " 2 0 2 0 0 2 0 3 0 1 1 1 0 0]\n",
      "original label:  [0 0 1 1 0 0 2 2 0 3 0 0 1 2 2 0 0 0 3 0 2 0 2 2 0 0 0 0 1 1 1 2 3 0 3 1 3\n",
      " 2 0 2 1 0 2 0 3 0 0 1 0 0 0]\n",
      "Test set results: loss= 0.2928 accuracy= 0.9020\n",
      "Epoch: 10.00 | loss train: 1.1647 | acc train: 0.4848\n",
      "Epoch: 20.00 | loss train: 1.0525 | acc train: 0.6435\n",
      "Epoch: 30.00 | loss train: 0.8646 | acc train: 0.6913\n",
      "Epoch: 40.00 | loss train: 0.6716 | acc train: 0.7457\n",
      "Epoch: 50.00 | loss train: 0.5096 | acc train: 0.8261\n",
      "Epoch: 60.00 | loss train: 0.4361 | acc train: 0.8478\n",
      "Epoch: 70.00 | loss train: 0.3688 | acc train: 0.8870\n",
      "Epoch: 80.00 | loss train: 0.3295 | acc train: 0.9043\n",
      "Epoch: 90.00 | loss train: 0.3108 | acc train: 0.8848\n",
      "Epoch: 100.00 | loss train: 0.2934 | acc train: 0.9196\n",
      "Epoch: 110.00 | loss train: 0.2781 | acc train: 0.9065\n",
      "Epoch: 120.00 | loss train: 0.2604 | acc train: 0.9196\n",
      "Epoch: 130.00 | loss train: 0.2645 | acc train: 0.9087\n",
      "Epoch: 140.00 | loss train: 0.2529 | acc train: 0.9174\n",
      "Epoch: 150.00 | loss train: 0.2433 | acc train: 0.9152\n",
      "predict label:  [0 0 0 2 0 1 0 1 2 3 0 3 0 2 0 0 0 2 2 3 0 0 0 0 2 3 1 1 0 0 1 1 0 1 0 1 2\n",
      " 2 0 0 0 0 2 0 0 3 0 0 2 0 2]\n",
      "original label:  [0 0 0 2 0 1 0 1 2 3 0 3 0 2 0 0 0 2 2 3 0 0 0 0 2 3 1 0 1 0 1 1 1 0 0 1 2\n",
      " 2 1 0 0 0 2 0 0 3 1 0 2 0 2]\n",
      "Test set results: loss= 0.3517 accuracy= 0.8824\n",
      "Epoch: 10.00 | loss train: 1.2165 | acc train: 0.4891\n",
      "Epoch: 20.00 | loss train: 1.0898 | acc train: 0.5761\n",
      "Epoch: 30.00 | loss train: 0.9155 | acc train: 0.6935\n",
      "Epoch: 40.00 | loss train: 0.7108 | acc train: 0.7196\n",
      "Epoch: 50.00 | loss train: 0.5591 | acc train: 0.8022\n",
      "Epoch: 60.00 | loss train: 0.4585 | acc train: 0.8522\n",
      "Epoch: 70.00 | loss train: 0.3937 | acc train: 0.8609\n",
      "Epoch: 80.00 | loss train: 0.3397 | acc train: 0.8543\n",
      "Epoch: 90.00 | loss train: 0.3006 | acc train: 0.8978\n",
      "Epoch: 100.00 | loss train: 0.2899 | acc train: 0.9087\n",
      "Epoch: 110.00 | loss train: 0.2819 | acc train: 0.9065\n",
      "Epoch: 120.00 | loss train: 0.2717 | acc train: 0.9130\n",
      "Epoch: 130.00 | loss train: 0.2476 | acc train: 0.9196\n",
      "Epoch: 140.00 | loss train: 0.2536 | acc train: 0.9130\n",
      "Epoch: 150.00 | loss train: 0.2614 | acc train: 0.9130\n",
      "predict label:  [2 0 2 2 0 0 0 0 0 3 1 2 0 0 2 0 0 1 0 2 0 0 2 2 0 0 3 1 3 3 1 0 0 0 1 3 0\n",
      " 0 2 0 0 0 2 1 1 0 0 0 0 2 0]\n",
      "original label:  [2 0 2 2 0 0 0 0 1 3 0 2 0 0 2 0 0 1 0 2 0 0 2 2 0 0 1 1 3 3 1 1 0 0 1 3 0\n",
      " 0 2 0 0 0 2 1 1 3 0 1 0 2 0]\n",
      "Test set results: loss= 0.3253 accuracy= 0.8824\n",
      "Epoch: 10.00 | loss train: 1.1973 | acc train: 0.4848\n",
      "Epoch: 20.00 | loss train: 1.0865 | acc train: 0.6152\n",
      "Epoch: 30.00 | loss train: 0.9077 | acc train: 0.7000\n",
      "Epoch: 40.00 | loss train: 0.7334 | acc train: 0.7152\n",
      "Epoch: 50.00 | loss train: 0.5701 | acc train: 0.7913\n",
      "Epoch: 60.00 | loss train: 0.4770 | acc train: 0.8413\n",
      "Epoch: 70.00 | loss train: 0.4124 | acc train: 0.8739\n",
      "Epoch: 80.00 | loss train: 0.3636 | acc train: 0.8761\n",
      "Epoch: 90.00 | loss train: 0.3273 | acc train: 0.8978\n",
      "Epoch: 100.00 | loss train: 0.3019 | acc train: 0.8913\n",
      "Epoch: 110.00 | loss train: 0.2983 | acc train: 0.8826\n",
      "Epoch: 120.00 | loss train: 0.2864 | acc train: 0.8957\n",
      "Epoch: 130.00 | loss train: 0.2512 | acc train: 0.9196\n",
      "Epoch: 140.00 | loss train: 0.2549 | acc train: 0.9196\n",
      "Epoch: 150.00 | loss train: 0.2571 | acc train: 0.9152\n",
      "predict label:  [2 0 2 3 0 2 1 0 2 0 3 0 0 0 0 2 3 1 2 0 2 2 1 3 1 0 0 2 0 0 0 0 0 0 3 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 1 3]\n",
      "original label:  [2 0 2 3 0 2 1 0 2 0 3 0 1 0 0 2 3 1 2 0 2 2 1 3 1 0 1 2 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 2 0 0 2 0 0 0 0 1 3]\n",
      "Test set results: loss= 0.3224 accuracy= 0.8824\n",
      "Epoch: 10.00 | loss train: 1.2192 | acc train: 0.4826\n",
      "Epoch: 20.00 | loss train: 1.0811 | acc train: 0.5674\n",
      "Epoch: 30.00 | loss train: 0.9019 | acc train: 0.7022\n",
      "Epoch: 40.00 | loss train: 0.7242 | acc train: 0.7217\n",
      "Epoch: 50.00 | loss train: 0.5698 | acc train: 0.7826\n",
      "Epoch: 60.00 | loss train: 0.4484 | acc train: 0.8304\n",
      "Epoch: 70.00 | loss train: 0.3969 | acc train: 0.8674\n",
      "Epoch: 80.00 | loss train: 0.3580 | acc train: 0.8696\n",
      "Epoch: 90.00 | loss train: 0.3401 | acc train: 0.8761\n",
      "Epoch: 100.00 | loss train: 0.3074 | acc train: 0.8848\n",
      "Epoch: 110.00 | loss train: 0.2980 | acc train: 0.9043\n",
      "Epoch: 120.00 | loss train: 0.2763 | acc train: 0.9022\n",
      "Epoch: 130.00 | loss train: 0.2638 | acc train: 0.9109\n",
      "Epoch: 140.00 | loss train: 0.2691 | acc train: 0.9174\n",
      "Epoch: 150.00 | loss train: 0.2607 | acc train: 0.9217\n",
      "predict label:  [0 0 2 0 0 0 1 2 0 0 0 0 1 2 1 0 2 2 2 0 0 0 1 0 3 0 0 1 0 0 3 3 1 2 2 3 0\n",
      " 2 0 0 0 0 1 0 2 2 1 0 0 0 0]\n",
      "original label:  [0 0 2 0 0 0 1 2 0 0 0 0 1 2 1 1 2 2 2 1 0 0 0 0 3 0 0 1 0 0 3 3 3 2 2 3 1\n",
      " 2 0 0 0 0 1 0 2 2 1 1 0 0 0]\n",
      "Test set results: loss= 0.2865 accuracy= 0.8824\n",
      "Epoch: 10.00 | loss train: 1.1852 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0641 | acc train: 0.5978\n",
      "Epoch: 30.00 | loss train: 0.8599 | acc train: 0.6957\n",
      "Epoch: 40.00 | loss train: 0.6790 | acc train: 0.7630\n",
      "Epoch: 50.00 | loss train: 0.5261 | acc train: 0.8413\n",
      "Epoch: 60.00 | loss train: 0.4218 | acc train: 0.8739\n",
      "Epoch: 70.00 | loss train: 0.3768 | acc train: 0.8543\n",
      "Epoch: 80.00 | loss train: 0.3411 | acc train: 0.8870\n",
      "Epoch: 90.00 | loss train: 0.3217 | acc train: 0.8913\n",
      "Epoch: 100.00 | loss train: 0.3216 | acc train: 0.8804\n",
      "Epoch: 110.00 | loss train: 0.3065 | acc train: 0.9022\n",
      "Epoch: 120.00 | loss train: 0.2814 | acc train: 0.9000\n",
      "Epoch: 130.00 | loss train: 0.2848 | acc train: 0.9109\n",
      "Epoch: 140.00 | loss train: 0.2595 | acc train: 0.9109\n",
      "Epoch: 150.00 | loss train: 0.2744 | acc train: 0.9174\n",
      "predict label:  [2 2 2 0 2 2 0 1 1 0 2 0 3 3 2 0 0 0 0 0 0 3 0 2 0 1 2 1 1 0 3 1 1 0 0 0 0\n",
      " 2 3 0 0 0 2 1 0 0 0 1 0 0 0]\n",
      "original label:  [2 2 2 0 2 2 0 1 1 0 2 0 3 3 2 0 0 0 0 0 0 3 0 2 0 0 2 1 1 1 3 1 1 1 0 0 0\n",
      " 2 3 0 0 0 2 1 0 0 0 1 0 0 0]\n",
      "Test set results: loss= 0.2029 accuracy= 0.9412\n",
      "Epoch: 10.00 | loss train: 1.1784 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0718 | acc train: 0.6370\n",
      "Epoch: 30.00 | loss train: 0.8698 | acc train: 0.6978\n",
      "Epoch: 40.00 | loss train: 0.6662 | acc train: 0.7348\n",
      "Epoch: 50.00 | loss train: 0.5275 | acc train: 0.8370\n",
      "Epoch: 60.00 | loss train: 0.4444 | acc train: 0.8565\n",
      "Epoch: 70.00 | loss train: 0.3908 | acc train: 0.8543\n",
      "Epoch: 80.00 | loss train: 0.3393 | acc train: 0.8804\n",
      "Epoch: 90.00 | loss train: 0.3108 | acc train: 0.8870\n",
      "Epoch: 100.00 | loss train: 0.3088 | acc train: 0.8978\n",
      "Epoch: 110.00 | loss train: 0.2878 | acc train: 0.9109\n",
      "Epoch: 120.00 | loss train: 0.2773 | acc train: 0.9196\n",
      "Epoch: 130.00 | loss train: 0.2621 | acc train: 0.9196\n",
      "Epoch: 140.00 | loss train: 0.2654 | acc train: 0.9152\n",
      "Epoch: 150.00 | loss train: 0.2621 | acc train: 0.9109\n",
      "predict label:  [0 0 0 2 0 0 1 2 0 2 0 2 0 2 2 0 0 2 1 0 3 0 0 1 2 1 1 3 2 0 0 1 0 1 2 0 0\n",
      " 0 0 0 0 1 1 3 1 1 0 2 3 0 2]\n",
      "original label:  [0 0 0 2 0 0 0 2 0 2 0 2 0 2 2 0 1 2 3 0 3 0 0 1 2 1 1 3 2 0 0 1 0 1 2 0 0\n",
      " 0 0 1 0 0 1 3 1 1 0 2 3 0 2]\n",
      "Test set results: loss= 0.1990 accuracy= 0.9020\n",
      "Epoch: 10.00 | loss train: 1.1953 | acc train: 0.4891\n",
      "Epoch: 20.00 | loss train: 1.0674 | acc train: 0.6022\n",
      "Epoch: 30.00 | loss train: 0.9136 | acc train: 0.6957\n",
      "Epoch: 40.00 | loss train: 0.7184 | acc train: 0.7065\n",
      "Epoch: 50.00 | loss train: 0.6020 | acc train: 0.7696\n",
      "Epoch: 60.00 | loss train: 0.5135 | acc train: 0.8196\n",
      "Epoch: 70.00 | loss train: 0.4278 | acc train: 0.8500\n",
      "Epoch: 80.00 | loss train: 0.3812 | acc train: 0.8565\n",
      "Epoch: 90.00 | loss train: 0.3492 | acc train: 0.8891\n",
      "Epoch: 100.00 | loss train: 0.3261 | acc train: 0.8870\n",
      "Epoch: 110.00 | loss train: 0.2857 | acc train: 0.9022\n",
      "Epoch: 120.00 | loss train: 0.3042 | acc train: 0.8870\n",
      "Epoch: 130.00 | loss train: 0.2881 | acc train: 0.8870\n",
      "Epoch: 140.00 | loss train: 0.2858 | acc train: 0.8870\n",
      "Epoch: 150.00 | loss train: 0.2590 | acc train: 0.9130\n",
      "predict label:  [0 2 0 2 0 0 0 0 0 2 3 1 0 1 2 2 0 0 0 0 0 1 0 2 0 1 2 1 0 3 2 0 0 0 1 1 1\n",
      " 2 1 0 1 1 1 0 0 1 2 0 0 2 2]\n",
      "original label:  [0 2 0 2 0 0 0 0 0 2 3 1 0 1 2 2 0 0 0 0 0 3 0 2 0 1 2 1 0 3 2 0 0 0 1 1 1\n",
      " 2 3 0 1 2 0 0 1 1 2 0 0 2 3]\n",
      "Test set results: loss= 0.3212 accuracy= 0.8824\n",
      "10-fold  Acc(0.8963, 0.0245)  F1(0.9014, 0.0210)\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "!python ../MoGCN/GCN_run.py -fd result/latent_data.csv -ad result/SNF_fused_matrix.csv -ld ./data/MoGCN/sample_classes.csv -ts ./data/MoGCN/test_sample.csv -m 0 -d gpu -p 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from modified GitHub repo code (original split)\n",
    "\n",
    "#### **Note: code has been modified to use AE and SNF without sharing training data when testing GCN**\n",
    "- predict label:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "- original label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 1 0 0 0 0 0 2 0 0\n",
    " 2 0 2 1 0 1 1 0 0 2 1 0 1 1 0 1 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
    "\n",
    "- Test set results: loss= 1.2201 accuracy= 0.5147\n",
    "- Acc(0.5147, 0.0000)  F1(0.6796, 0.0000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "epoch: 1 | loss: 57.3638\n",
      "epoch: 2 | loss: 38.5932\n",
      "epoch: 3 | loss: 26.1857\n",
      "epoch: 4 | loss: 18.0734\n",
      "epoch: 5 | loss: 12.9168\n",
      "epoch: 6 | loss: 9.6933\n",
      "epoch: 7 | loss: 7.6876\n",
      "epoch: 8 | loss: 6.4357\n",
      "epoch: 9 | loss: 5.6580\n",
      "epoch: 10 | loss: 5.1476\n",
      "epoch: 11 | loss: 4.8289\n",
      "epoch: 12 | loss: 4.6105\n",
      "epoch: 13 | loss: 4.4597\n",
      "epoch: 14 | loss: 4.3564\n",
      "epoch: 15 | loss: 4.2778\n",
      "epoch: 16 | loss: 4.2156\n",
      "epoch: 17 | loss: 4.1681\n",
      "epoch: 18 | loss: 4.1204\n",
      "epoch: 19 | loss: 4.0776\n",
      "epoch: 20 | loss: 4.0348\n",
      "epoch: 21 | loss: 3.9958\n",
      "epoch: 22 | loss: 3.9669\n",
      "epoch: 23 | loss: 3.9321\n",
      "epoch: 24 | loss: 3.8903\n",
      "epoch: 25 | loss: 3.8571\n",
      "epoch: 26 | loss: 3.8225\n",
      "epoch: 27 | loss: 3.7921\n",
      "epoch: 28 | loss: 3.7584\n",
      "epoch: 29 | loss: 3.7281\n",
      "epoch: 30 | loss: 3.6831\n",
      "epoch: 31 | loss: 3.6689\n",
      "epoch: 32 | loss: 3.6315\n",
      "epoch: 33 | loss: 3.6099\n",
      "epoch: 34 | loss: 3.5866\n",
      "epoch: 35 | loss: 3.5649\n",
      "epoch: 36 | loss: 3.5523\n",
      "epoch: 37 | loss: 3.5083\n",
      "epoch: 38 | loss: 3.4925\n",
      "epoch: 39 | loss: 3.4559\n",
      "epoch: 40 | loss: 3.4470\n",
      "epoch: 41 | loss: 3.4110\n",
      "epoch: 42 | loss: 3.4016\n",
      "epoch: 43 | loss: 3.3725\n",
      "epoch: 44 | loss: 3.3391\n",
      "epoch: 45 | loss: 3.3254\n",
      "epoch: 46 | loss: 3.3037\n",
      "epoch: 47 | loss: 3.2888\n",
      "epoch: 48 | loss: 3.2629\n",
      "epoch: 49 | loss: 3.2483\n",
      "epoch: 50 | loss: 3.2183\n",
      "epoch: 51 | loss: 3.2007\n",
      "epoch: 52 | loss: 3.1755\n",
      "epoch: 53 | loss: 3.1738\n",
      "epoch: 54 | loss: 3.1413\n",
      "epoch: 55 | loss: 3.1274\n",
      "epoch: 56 | loss: 3.1204\n",
      "epoch: 57 | loss: 3.1022\n",
      "epoch: 58 | loss: 3.0619\n",
      "epoch: 59 | loss: 3.0429\n",
      "epoch: 60 | loss: 3.0245\n",
      "epoch: 61 | loss: 3.0123\n",
      "epoch: 62 | loss: 3.0025\n",
      "epoch: 63 | loss: 2.9868\n",
      "epoch: 64 | loss: 2.9716\n",
      "epoch: 65 | loss: 2.9398\n",
      "epoch: 66 | loss: 2.9217\n",
      "epoch: 67 | loss: 2.9053\n",
      "epoch: 68 | loss: 2.9061\n",
      "epoch: 69 | loss: 2.8854\n",
      "epoch: 70 | loss: 2.8666\n",
      "epoch: 71 | loss: 2.8460\n",
      "epoch: 72 | loss: 2.8309\n",
      "epoch: 73 | loss: 2.8083\n",
      "epoch: 74 | loss: 2.8182\n",
      "epoch: 75 | loss: 2.7853\n",
      "epoch: 76 | loss: 2.7737\n",
      "epoch: 77 | loss: 2.7663\n",
      "epoch: 78 | loss: 2.7460\n",
      "epoch: 79 | loss: 2.7226\n",
      "epoch: 80 | loss: 2.7282\n",
      "epoch: 81 | loss: 2.6927\n",
      "epoch: 82 | loss: 2.6811\n",
      "epoch: 83 | loss: 2.6793\n",
      "epoch: 84 | loss: 2.6567\n",
      "epoch: 85 | loss: 2.6457\n",
      "epoch: 86 | loss: 2.6279\n",
      "epoch: 87 | loss: 2.6070\n",
      "epoch: 88 | loss: 2.6073\n",
      "epoch: 89 | loss: 2.5903\n",
      "epoch: 90 | loss: 2.5918\n",
      "epoch: 91 | loss: 2.5725\n",
      "epoch: 92 | loss: 2.5570\n",
      "epoch: 93 | loss: 2.5453\n",
      "epoch: 94 | loss: 2.5403\n",
      "epoch: 95 | loss: 2.5399\n",
      "epoch: 96 | loss: 2.5359\n",
      "epoch: 97 | loss: 2.5054\n",
      "epoch: 98 | loss: 2.4883\n",
      "epoch: 99 | loss: 2.4789\n",
      "epoch: 100 | loss: 2.4549\n",
      "Get the latent layer output...\n",
      "Success! Results can be seen in result file\n"
     ]
    }
   ],
   "source": [
    "!python ../MoGCN/AE_run.py -p1 ./data/original_split/train/fpkm_data.csv -p2 ./data/original_split/train/gistic_data.csv -p3 ./data/original_split/train/rppa_data.csv -m 0 -s 0 -d cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the latent layer output...\n",
      "Success! Results can be seen in result file\n"
     ]
    }
   ],
   "source": [
    "!python ../MoGCN/AE_run.py -p1 ./data/MoGCN/fpkm_data.csv -p2 ./data/MoGCN/gistic_data.csv -p3 ./data/MoGCN/rppa_data.csv -m 2 -s 0 -d cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data files...\n",
      "(511, 19581) (511, 19274) (511, 224)\n",
      "Start similarity network fusion...\n",
      "Save fused adjacency matrix...\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:530: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage = hierarchy.linkage(self.array, method=self.method,\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/home/davide/miniconda3/envs/omics/lib/python3.11/site-packages/seaborn/matrix.py:530: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage = hierarchy.linkage(self.array, method=self.method,\n",
      "Success! Results can be seen in result file\n"
     ]
    }
   ],
   "source": [
    "!python ../MoGCN/SNF.py -p ./data/MoGCN/fpkm_data.csv ./data/MoGCN/gistic_data.csv ./data/MoGCN/rppa_data.csv -m sqeuclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Calculating the laplace adjacency matrix...\n",
      "Begin training model...\n",
      "Epoch: 10.00 | loss train: 1.2026 | acc train: 0.4858\n",
      "Epoch: 20.00 | loss train: 1.0916 | acc train: 0.5577\n",
      "Epoch: 30.00 | loss train: 0.9474 | acc train: 0.6776\n",
      "Epoch: 40.00 | loss train: 0.7458 | acc train: 0.7168\n",
      "Epoch: 50.00 | loss train: 0.5812 | acc train: 0.7712\n",
      "Epoch: 60.00 | loss train: 0.4827 | acc train: 0.8279\n",
      "Epoch: 70.00 | loss train: 0.4332 | acc train: 0.8519\n",
      "Epoch: 80.00 | loss train: 0.3737 | acc train: 0.8758\n",
      "Epoch: 90.00 | loss train: 0.3533 | acc train: 0.8845\n",
      "Epoch: 100.00 | loss train: 0.3186 | acc train: 0.8954\n",
      "Epoch: 110.00 | loss train: 0.3000 | acc train: 0.8954\n",
      "Epoch: 120.00 | loss train: 0.2846 | acc train: 0.9041\n",
      "Epoch: 130.00 | loss train: 0.2913 | acc train: 0.8998\n",
      "Epoch: 140.00 | loss train: 0.2655 | acc train: 0.9020\n",
      "Epoch: 150.00 | loss train: 0.2704 | acc train: 0.9063\n",
      "predict label:  [2 3 0 0 0 0 0 3 0 0 2 2 1 2 2 0 0 0 0 3 0 0 0 0 2 0 0 3 0 3 0 0 2 3 1 0 1\n",
      " 0 1 0 0 2 2 3 2 0 2 3 0 1 0 0]\n",
      "original label:  [2 3 0 0 0 0 0 3 0 0 2 2 1 2 2 0 0 0 0 3 0 0 0 0 2 0 0 3 0 3 1 0 2 1 1 0 1\n",
      " 0 1 0 0 2 2 3 2 1 2 1 0 1 0 1]\n",
      "Test set results: loss= 0.2819 accuracy= 0.9038\n",
      "Epoch: 10.00 | loss train: 1.1986 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0390 | acc train: 0.6500\n",
      "Epoch: 30.00 | loss train: 0.8474 | acc train: 0.7022\n",
      "Epoch: 40.00 | loss train: 0.6595 | acc train: 0.7326\n",
      "Epoch: 50.00 | loss train: 0.5349 | acc train: 0.8174\n",
      "Epoch: 60.00 | loss train: 0.4531 | acc train: 0.8457\n",
      "Epoch: 70.00 | loss train: 0.4054 | acc train: 0.8674\n",
      "Epoch: 80.00 | loss train: 0.3712 | acc train: 0.8674\n",
      "Epoch: 90.00 | loss train: 0.3292 | acc train: 0.8761\n",
      "Epoch: 100.00 | loss train: 0.3079 | acc train: 0.8957\n",
      "Epoch: 110.00 | loss train: 0.3079 | acc train: 0.8935\n",
      "Epoch: 120.00 | loss train: 0.2941 | acc train: 0.9000\n",
      "Epoch: 130.00 | loss train: 0.3101 | acc train: 0.8913\n",
      "Epoch: 140.00 | loss train: 0.2888 | acc train: 0.9000\n",
      "Epoch: 150.00 | loss train: 0.2661 | acc train: 0.9130\n",
      "predict label:  [2 3 0 1 0 0 0 1 3 1 2 2 0 2 2 2 1 0 2 0 0 1 0 0 2 0 0 0 0 3 3 2 2 3 3 1 0\n",
      " 0 1 0 0 0 3 0 0 0 1 0 1 0 0]\n",
      "original label:  [2 3 0 1 1 0 0 1 3 1 2 2 0 2 2 2 1 0 2 0 0 1 0 0 2 0 0 0 0 3 3 2 2 3 2 1 0\n",
      " 0 1 0 0 0 3 0 0 0 1 0 0 0 0]\n",
      "Test set results: loss= 0.2238 accuracy= 0.9412\n",
      "Epoch: 10.00 | loss train: 1.1659 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0455 | acc train: 0.5717\n",
      "Epoch: 30.00 | loss train: 0.8823 | acc train: 0.7000\n",
      "Epoch: 40.00 | loss train: 0.7033 | acc train: 0.7435\n",
      "Epoch: 50.00 | loss train: 0.5579 | acc train: 0.7870\n",
      "Epoch: 60.00 | loss train: 0.4468 | acc train: 0.8478\n",
      "Epoch: 70.00 | loss train: 0.3839 | acc train: 0.8674\n",
      "Epoch: 80.00 | loss train: 0.3399 | acc train: 0.8826\n",
      "Epoch: 90.00 | loss train: 0.3196 | acc train: 0.9043\n",
      "Epoch: 100.00 | loss train: 0.2891 | acc train: 0.9043\n",
      "Epoch: 110.00 | loss train: 0.2996 | acc train: 0.8913\n",
      "Epoch: 120.00 | loss train: 0.2702 | acc train: 0.9174\n",
      "Epoch: 130.00 | loss train: 0.2868 | acc train: 0.9109\n",
      "Epoch: 140.00 | loss train: 0.2582 | acc train: 0.9130\n",
      "Epoch: 150.00 | loss train: 0.2477 | acc train: 0.9239\n",
      "predict label:  [0 0 1 0 0 0 2 2 0 3 0 0 0 2 2 0 0 0 3 0 2 0 2 2 0 0 0 0 1 1 1 2 3 0 3 1 3\n",
      " 2 0 2 0 0 2 0 3 0 1 1 1 0 0]\n",
      "original label:  [0 0 1 1 0 0 2 2 0 3 0 0 1 2 2 0 0 0 3 0 2 0 2 2 0 0 0 0 1 1 1 2 3 0 3 1 3\n",
      " 2 0 2 1 0 2 0 3 0 0 1 0 0 0]\n",
      "Test set results: loss= 0.3187 accuracy= 0.9020\n",
      "Epoch: 10.00 | loss train: 1.1681 | acc train: 0.4848\n",
      "Epoch: 20.00 | loss train: 1.0619 | acc train: 0.6391\n",
      "Epoch: 30.00 | loss train: 0.8795 | acc train: 0.6913\n",
      "Epoch: 40.00 | loss train: 0.6861 | acc train: 0.7391\n",
      "Epoch: 50.00 | loss train: 0.5232 | acc train: 0.8152\n",
      "Epoch: 60.00 | loss train: 0.4473 | acc train: 0.8457\n",
      "Epoch: 70.00 | loss train: 0.3807 | acc train: 0.8739\n",
      "Epoch: 80.00 | loss train: 0.3395 | acc train: 0.9043\n",
      "Epoch: 90.00 | loss train: 0.3199 | acc train: 0.8826\n",
      "Epoch: 100.00 | loss train: 0.3021 | acc train: 0.9087\n",
      "Epoch: 110.00 | loss train: 0.2886 | acc train: 0.9087\n",
      "Epoch: 120.00 | loss train: 0.2731 | acc train: 0.9152\n",
      "Epoch: 130.00 | loss train: 0.2773 | acc train: 0.9065\n",
      "Epoch: 140.00 | loss train: 0.2654 | acc train: 0.9109\n",
      "Epoch: 150.00 | loss train: 0.2553 | acc train: 0.9043\n",
      "predict label:  [0 0 0 2 0 1 0 1 2 3 0 3 0 2 0 0 0 2 2 3 0 0 0 0 2 3 1 1 0 0 1 1 0 1 0 1 2\n",
      " 2 1 0 0 0 2 0 0 3 0 0 2 0 2]\n",
      "original label:  [0 0 0 2 0 1 0 1 2 3 0 3 0 2 0 0 0 2 2 3 0 0 0 0 2 3 1 0 1 0 1 1 1 0 0 1 2\n",
      " 2 1 0 0 0 2 0 0 3 1 0 2 0 2]\n",
      "Test set results: loss= 0.3411 accuracy= 0.9020\n",
      "Epoch: 10.00 | loss train: 1.2187 | acc train: 0.4891\n",
      "Epoch: 20.00 | loss train: 1.0934 | acc train: 0.5739\n",
      "Epoch: 30.00 | loss train: 0.9253 | acc train: 0.6891\n",
      "Epoch: 40.00 | loss train: 0.7256 | acc train: 0.7152\n",
      "Epoch: 50.00 | loss train: 0.5720 | acc train: 0.7891\n",
      "Epoch: 60.00 | loss train: 0.4714 | acc train: 0.8522\n",
      "Epoch: 70.00 | loss train: 0.4052 | acc train: 0.8522\n",
      "Epoch: 80.00 | loss train: 0.3490 | acc train: 0.8478\n",
      "Epoch: 90.00 | loss train: 0.3115 | acc train: 0.8978\n",
      "Epoch: 100.00 | loss train: 0.3020 | acc train: 0.8978\n",
      "Epoch: 110.00 | loss train: 0.2905 | acc train: 0.9000\n",
      "Epoch: 120.00 | loss train: 0.2809 | acc train: 0.9087\n",
      "Epoch: 130.00 | loss train: 0.2583 | acc train: 0.9152\n",
      "Epoch: 140.00 | loss train: 0.2674 | acc train: 0.9087\n",
      "Epoch: 150.00 | loss train: 0.2749 | acc train: 0.8978\n",
      "predict label:  [2 0 2 2 0 0 0 0 0 3 1 2 0 0 2 0 0 1 0 2 0 0 2 2 0 0 3 1 3 3 1 0 0 0 1 3 0\n",
      " 0 2 0 0 0 2 1 1 0 0 1 0 2 0]\n",
      "original label:  [2 0 2 2 0 0 0 0 1 3 0 2 0 0 2 0 0 1 0 2 0 0 2 2 0 0 1 1 3 3 1 1 0 0 1 3 0\n",
      " 0 2 0 0 0 2 1 1 3 0 1 0 2 0]\n",
      "Test set results: loss= 0.3299 accuracy= 0.9020\n",
      "Epoch: 10.00 | loss train: 1.2011 | acc train: 0.4848\n",
      "Epoch: 20.00 | loss train: 1.0938 | acc train: 0.6022\n",
      "Epoch: 30.00 | loss train: 0.9209 | acc train: 0.6978\n",
      "Epoch: 40.00 | loss train: 0.7492 | acc train: 0.7109\n",
      "Epoch: 50.00 | loss train: 0.5837 | acc train: 0.7848\n",
      "Epoch: 60.00 | loss train: 0.4877 | acc train: 0.8326\n",
      "Epoch: 70.00 | loss train: 0.4222 | acc train: 0.8630\n",
      "Epoch: 80.00 | loss train: 0.3729 | acc train: 0.8696\n",
      "Epoch: 90.00 | loss train: 0.3363 | acc train: 0.8826\n",
      "Epoch: 100.00 | loss train: 0.3136 | acc train: 0.8848\n",
      "Epoch: 110.00 | loss train: 0.3074 | acc train: 0.8848\n",
      "Epoch: 120.00 | loss train: 0.2973 | acc train: 0.8978\n",
      "Epoch: 130.00 | loss train: 0.2627 | acc train: 0.9217\n",
      "Epoch: 140.00 | loss train: 0.2653 | acc train: 0.9130\n",
      "Epoch: 150.00 | loss train: 0.2682 | acc train: 0.9065\n",
      "predict label:  [2 0 2 3 0 2 0 0 2 0 3 0 0 0 0 2 3 1 2 0 2 2 1 3 1 0 0 2 0 0 0 0 0 0 3 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 3]\n",
      "original label:  [2 0 2 3 0 2 1 0 2 0 3 0 1 0 0 2 3 1 2 0 2 2 1 3 1 0 1 2 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 2 0 0 2 0 0 0 0 1 3]\n",
      "Test set results: loss= 0.3467 accuracy= 0.8431\n",
      "Epoch: 10.00 | loss train: 1.2216 | acc train: 0.4826\n",
      "Epoch: 20.00 | loss train: 1.0881 | acc train: 0.5696\n",
      "Epoch: 30.00 | loss train: 0.9154 | acc train: 0.6935\n",
      "Epoch: 40.00 | loss train: 0.7386 | acc train: 0.7174\n",
      "Epoch: 50.00 | loss train: 0.5805 | acc train: 0.7804\n",
      "Epoch: 60.00 | loss train: 0.4583 | acc train: 0.8239\n",
      "Epoch: 70.00 | loss train: 0.4094 | acc train: 0.8652\n",
      "Epoch: 80.00 | loss train: 0.3680 | acc train: 0.8739\n",
      "Epoch: 90.00 | loss train: 0.3499 | acc train: 0.8696\n",
      "Epoch: 100.00 | loss train: 0.3193 | acc train: 0.8761\n",
      "Epoch: 110.00 | loss train: 0.3127 | acc train: 0.9022\n",
      "Epoch: 120.00 | loss train: 0.2897 | acc train: 0.9043\n",
      "Epoch: 130.00 | loss train: 0.2775 | acc train: 0.9022\n",
      "Epoch: 140.00 | loss train: 0.2829 | acc train: 0.9130\n",
      "Epoch: 150.00 | loss train: 0.2751 | acc train: 0.9130\n",
      "predict label:  [0 0 2 0 0 0 1 2 0 0 0 0 1 2 1 0 2 2 2 0 0 0 1 0 3 0 0 1 0 0 3 3 1 2 2 3 0\n",
      " 2 0 0 0 0 1 0 2 2 1 0 0 0 0]\n",
      "original label:  [0 0 2 0 0 0 1 2 0 0 0 0 1 2 1 1 2 2 2 1 0 0 0 0 3 0 0 1 0 0 3 3 3 2 2 3 1\n",
      " 2 0 0 0 0 1 0 2 2 1 1 0 0 0]\n",
      "Test set results: loss= 0.2829 accuracy= 0.8824\n",
      "Epoch: 10.00 | loss train: 1.1902 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0748 | acc train: 0.5913\n",
      "Epoch: 30.00 | loss train: 0.8777 | acc train: 0.6848\n",
      "Epoch: 40.00 | loss train: 0.6976 | acc train: 0.7478\n",
      "Epoch: 50.00 | loss train: 0.5413 | acc train: 0.8283\n",
      "Epoch: 60.00 | loss train: 0.4343 | acc train: 0.8674\n",
      "Epoch: 70.00 | loss train: 0.3896 | acc train: 0.8500\n",
      "Epoch: 80.00 | loss train: 0.3534 | acc train: 0.8870\n",
      "Epoch: 90.00 | loss train: 0.3325 | acc train: 0.8804\n",
      "Epoch: 100.00 | loss train: 0.3318 | acc train: 0.8804\n",
      "Epoch: 110.00 | loss train: 0.3180 | acc train: 0.8891\n",
      "Epoch: 120.00 | loss train: 0.2884 | acc train: 0.9000\n",
      "Epoch: 130.00 | loss train: 0.2958 | acc train: 0.9065\n",
      "Epoch: 140.00 | loss train: 0.2719 | acc train: 0.9109\n",
      "Epoch: 150.00 | loss train: 0.2866 | acc train: 0.9065\n",
      "predict label:  [2 2 2 0 2 2 0 1 1 0 2 0 3 3 2 0 0 0 0 0 0 3 0 2 0 1 2 1 1 0 3 1 1 0 0 0 0\n",
      " 2 3 0 0 0 2 1 0 0 0 1 0 0 0]\n",
      "original label:  [2 2 2 0 2 2 0 1 1 0 2 0 3 3 2 0 0 0 0 0 0 3 0 2 0 0 2 1 1 1 3 1 1 1 0 0 0\n",
      " 2 3 0 0 0 2 1 0 0 0 1 0 0 0]\n",
      "Test set results: loss= 0.2132 accuracy= 0.9412\n",
      "Epoch: 10.00 | loss train: 1.1788 | acc train: 0.4870\n",
      "Epoch: 20.00 | loss train: 1.0747 | acc train: 0.6348\n",
      "Epoch: 30.00 | loss train: 0.8778 | acc train: 0.6935\n",
      "Epoch: 40.00 | loss train: 0.6759 | acc train: 0.7304\n",
      "Epoch: 50.00 | loss train: 0.5363 | acc train: 0.8370\n",
      "Epoch: 60.00 | loss train: 0.4524 | acc train: 0.8457\n",
      "Epoch: 70.00 | loss train: 0.3980 | acc train: 0.8500\n",
      "Epoch: 80.00 | loss train: 0.3481 | acc train: 0.8717\n",
      "Epoch: 90.00 | loss train: 0.3205 | acc train: 0.8891\n",
      "Epoch: 100.00 | loss train: 0.3174 | acc train: 0.8891\n",
      "Epoch: 110.00 | loss train: 0.2977 | acc train: 0.9043\n",
      "Epoch: 120.00 | loss train: 0.2909 | acc train: 0.9087\n",
      "Epoch: 130.00 | loss train: 0.2749 | acc train: 0.9043\n",
      "Epoch: 140.00 | loss train: 0.2770 | acc train: 0.9065\n",
      "Epoch: 150.00 | loss train: 0.2728 | acc train: 0.9109\n",
      "predict label:  [0 0 0 2 0 0 1 2 0 2 0 2 0 2 2 0 0 2 1 0 3 0 0 1 2 1 1 3 2 0 0 1 0 1 2 0 0\n",
      " 0 0 1 0 1 1 3 1 1 0 2 3 0 2]\n",
      "original label:  [0 0 0 2 0 0 0 2 0 2 0 2 0 2 2 0 1 2 3 0 3 0 0 1 2 1 1 3 2 0 0 1 0 1 2 0 0\n",
      " 0 0 1 0 0 1 3 1 1 0 2 3 0 2]\n",
      "Test set results: loss= 0.2000 accuracy= 0.9216\n",
      "Epoch: 10.00 | loss train: 1.1960 | acc train: 0.4891\n",
      "Epoch: 20.00 | loss train: 1.0715 | acc train: 0.6022\n",
      "Epoch: 30.00 | loss train: 0.9235 | acc train: 0.6935\n",
      "Epoch: 40.00 | loss train: 0.7293 | acc train: 0.7109\n",
      "Epoch: 50.00 | loss train: 0.6108 | acc train: 0.7696\n",
      "Epoch: 60.00 | loss train: 0.5264 | acc train: 0.8065\n",
      "Epoch: 70.00 | loss train: 0.4405 | acc train: 0.8500\n",
      "Epoch: 80.00 | loss train: 0.3903 | acc train: 0.8565\n",
      "Epoch: 90.00 | loss train: 0.3582 | acc train: 0.8891\n",
      "Epoch: 100.00 | loss train: 0.3355 | acc train: 0.8783\n",
      "Epoch: 110.00 | loss train: 0.2955 | acc train: 0.8978\n",
      "Epoch: 120.00 | loss train: 0.3165 | acc train: 0.8783\n",
      "Epoch: 130.00 | loss train: 0.3004 | acc train: 0.8848\n",
      "Epoch: 140.00 | loss train: 0.2968 | acc train: 0.8783\n",
      "Epoch: 150.00 | loss train: 0.2712 | acc train: 0.9065\n",
      "predict label:  [0 2 0 2 0 0 0 0 0 2 3 1 0 1 2 2 0 0 0 0 0 1 0 2 0 1 2 1 0 3 2 0 0 0 1 1 1\n",
      " 2 1 0 1 1 1 0 0 1 2 0 0 2 2]\n",
      "original label:  [0 2 0 2 0 0 0 0 0 2 3 1 0 1 2 2 0 0 0 0 0 3 0 2 0 1 2 1 0 3 2 0 0 0 1 1 1\n",
      " 2 3 0 1 2 0 0 1 1 2 0 0 2 3]\n",
      "Test set results: loss= 0.3316 accuracy= 0.8824\n",
      "10-fold  Acc(0.9021, 0.0277)  F1(0.9078, 0.0216)\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "!python ../MoGCN/GCN_run.py -fd result/latent_data.csv -ad result/SNF_fused_matrix.csv -ld ./data/MoGCN/sample_classes.csv -ts ./data/MoGCN/test_sample.csv -m 0 -d gpu -p 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Calculating the laplace adjacency matrix...\n",
      "Begin training model...\n",
      "Epoch: 10.00 | loss train: 1.2149 | acc train: 0.4808\n",
      "Epoch: 20.00 | loss train: 1.1015 | acc train: 0.5214\n",
      "Epoch: 30.00 | loss train: 0.9621 | acc train: 0.6569\n",
      "Epoch: 40.00 | loss train: 0.7605 | acc train: 0.7088\n",
      "Epoch: 50.00 | loss train: 0.5906 | acc train: 0.7675\n",
      "Epoch: 60.00 | loss train: 0.4902 | acc train: 0.8307\n",
      "Epoch: 70.00 | loss train: 0.4402 | acc train: 0.8510\n",
      "Epoch: 80.00 | loss train: 0.3849 | acc train: 0.8713\n",
      "Epoch: 90.00 | loss train: 0.3670 | acc train: 0.8736\n",
      "Epoch: 100.00 | loss train: 0.3262 | acc train: 0.8939\n",
      "Epoch: 110.00 | loss train: 0.3107 | acc train: 0.8894\n",
      "Epoch: 120.00 | loss train: 0.2994 | acc train: 0.9074\n",
      "Epoch: 130.00 | loss train: 0.3023 | acc train: 0.9074\n",
      "Epoch: 140.00 | loss train: 0.2819 | acc train: 0.9029\n",
      "Epoch: 150.00 | loss train: 0.2981 | acc train: 0.9007\n",
      "Training finished.\n",
      "The best epoch model is  145\n",
      "predict label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 0 0 0 0 0 0 2 0 0\n",
      " 2 0 2 1 0 1 0 0 0 2 0 0 1 0 1 1 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
      "original label:  [0 0 2 2 0 0 2 2 2 3 2 0 0 3 2 2 0 0 0 0 0 0 0 2 2 2 3 2 1 0 0 0 0 0 2 0 0\n",
      " 2 0 2 1 0 1 1 0 0 2 1 0 1 1 0 1 2 0 0 0 2 0 0 0 2 0 0 2 2 0 2]\n",
      "Test set results: loss= 0.1443 accuracy= 0.9265\n",
      "Acc(0.9265, 0.0000)  F1(0.9334, 0.0000)\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "!python ../MoGCN/GCN_run.py -fd result/latent_data.csv -ad result/SNF_fused_matrix.csv -ld ./data/MoGCN/sample_classes.csv -ts ./data/MoGCN/test_sample.csv -m 1 -d gpu -p 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
